{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import os.path\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import math\n",
    "import openpyxl\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SABI 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J. 360001-405000.xlsx', 'G. 225001-270000.xlsx', 'D. 135001-180000.xlsx', 'F. 185001-225000.xlsx', 'C. 90001-135000.xlsx', 'K. 405001-450000.xlsx', 'L. 450001-495000.xlsx', 'H. 270001-315000.xlsx', 'A. 1-45000.xlsx', 'B. 45001-90000.xlsx', 'I. 315001-360000.xlsx', 'M. 495001-532592.xlsx', 'E. 180001-185000.xlsx']\n"
     ]
    }
   ],
   "source": [
    "counter_file_name = 'file_processed_counter'\n",
    "\n",
    "path1 = '/home/ec2-user/proyecto/data/datasets/SABI2/'\n",
    "onlyfiles1 = [f for f in listdir(path1) if isfile(join(path1, f))]\n",
    "\n",
    "#Cargamos en un vector, la lista de los ficheros que se van procesando, por si se cae el jupyter, no volver a procesar todos\n",
    "#Sino proseguir con aquellos que no se han procesado.\n",
    "if (not(os.path.isfile(counter_file_name))):\n",
    "    with open(counter_file_name, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(onlyfiles1, dumpPickleCounter)\n",
    "else:\n",
    "    with open(counter_file_name, 'rb') as dumpPickleCounter:\n",
    "        onlyfiles1 = pickle.load(dumpPickleCounter)\n",
    "\n",
    "print onlyfiles1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las columnas que vamos a coger para cada DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfwork_cols = [1,2,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,26,27,29,56,57,58,59,60,61,62,63,64,65,66,54,55,67,68,69,70]\n",
    "dfaudit_cols = [1,2,35,36,37,38,39]\n",
    "dfParticipadas_cols = [1,2,48,49,50,51,52,53]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer fichero: 13 Lista1 Empresas 68401-74101.xlsx\n",
      "Resto ficheros: 26 Lista1 Empresas 142502-148201.xlsx\n",
      "Resto ficheros: 38 Lista1 Empresas 210902_216601.xlsx\n",
      "Resto ficheros: 01 Lista1 Empresas 1-5700.xlsx\n",
      "Resto ficheros: 02 Lista1 Empresas 5701-11400.xlsx\n",
      "Resto ficheros: 03 Lista1 Empresas 11401 -17001.xlsx\n",
      "Resto ficheros: 04 Lista1 Empresas 17402-22801.xlsx\n",
      "Resto ficheros: 05 Lista1 Empresas 22802-28501.xlsx\n",
      "Resto ficheros: 06 Lista1 Empresas 28502-34201.xlsx\n",
      "Resto ficheros: 07 Lista1 Empresas 34202-39901.xlsx\n",
      "Resto ficheros: 08 Lista1 Empresas 39902-45601.xlsx\n",
      "Resto ficheros: 09 Lista1 Empresas 45602-51301.xlsx\n",
      "Resto ficheros: 10 Lista1 Empresas 51302-57001.xlsx\n",
      "Resto ficheros: 11 Lista1 Empresas 57002-62701.xlsx\n",
      "Resto ficheros: 12 Lista1 Empresas 62702-68401.xlsx\n",
      "Resto ficheros: 14 Lista1 Empresas 74102-79801.xlsx\n",
      "Resto ficheros: 15 Lista1 Empresas 79802-85501.xlsx\n",
      "Resto ficheros: 16 Lista1 Empresas 85502-91201.xlsx\n",
      "Resto ficheros: 17 Lista1 Empresas 91201-96901.xlsx\n",
      "Resto ficheros: 18 Lista1 Empresas 96902-102601.xlsx\n",
      "Resto ficheros: 19 Lista1 Empresas 102602-108301.xlsx\n",
      "Resto ficheros: 20 Lista1 Empresas 108301-114001.xlsx\n",
      "Resto ficheros: 21 Lista1 Empresas 114002-119701.xlsx\n",
      "Resto ficheros: 22 Lista 1 Empresas 119701-125401.xlsx\n",
      "Resto ficheros: 23 Lista1 Empresas 125402-131101.xlsx\n",
      "Resto ficheros: 24 Lista1 Empresas 131102_136801.xlsx\n",
      "Resto ficheros: 25 Lista1 Empresas 136802-142501.xlsx\n",
      "Resto ficheros: 27 lista1 Empresas 148202-153901.xlsx\n",
      "Resto ficheros: 28 Lista1 Empresas 153902-159601.xlsx\n",
      "Resto ficheros: 29 Lista1 Empresas 159602-165301.xlsx\n",
      "Resto ficheros: 30 Lista1 Empresas 165301-171001.xlsx\n",
      "Resto ficheros: 31 Lista1 Empresas 171002_176701.xlsx\n",
      "Resto ficheros: 32 Lista1 Empresas 176702_182401.xlsx\n",
      "Resto ficheros: 33 Lista1 Empresas 182402-188101.xlsx\n",
      "Resto ficheros: 34 Lista1 Empresas 188102-193801.xlsx\n",
      "Resto ficheros: 35 Lista1 Empresas 193802-199501.xlsx\n",
      "Resto ficheros: 36 Lista1 Empresas 199502_205201.xlsx\n",
      "Resto ficheros: 37 Lista1 Empresas 205202_210901.xlsx\n",
      "Resto ficheros: 39 Lista1 Empresas 216602_222301.xlsx\n",
      "Resto ficheros: 40 Lista1 Empresas 222302_228001.xlsx\n",
      "Resto ficheros: 41 Lista1 Empresas 228002_233701.xlsx\n",
      "Resto ficheros: 42 Lista1 Empresas 233702_239401 (1).xlsx\n",
      "Resto ficheros: 43 Lista1 Empresas 239402_245101.xlsx\n",
      "Resto ficheros: 44 Lista1 Empresas 245102_250801.xlsx\n",
      "Resto ficheros: 45 Lista1 Empresas 250000_254000.xlsx\n",
      "Resto ficheros: 46 Lista1 Empresas 254001_259000.xlsx\n",
      "Resto ficheros: 47 Lista1 Empresas 259001_264000.xlsx\n",
      "Resto ficheros: 48 Lista1 Empresas 264001_269000.xlsx\n",
      "Resto ficheros: 49 Lista1 Empresas 269001_274000.xlsx\n",
      "Resto ficheros: 50 Lista1 empresas 274001_279000.xlsx\n",
      "Resto ficheros: 51 Lista1 Empresas 279001_280115.xlsx\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "dfwork = pd.DataFrame()\n",
    "dfaudit = pd.DataFrame()\n",
    "dfparticipadas = pd.DataFrame()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for f in list(onlyfiles1):\n",
    "    io = join(path1, f)\n",
    "    if counter==0:\n",
    "        print 'Primer fichero:', f\n",
    "        df = pd.read_excel(io, sheetname='Resultados', index_col=None, header=0, skiprows=0, na_values=None, thousands=None)\n",
    "        \n",
    "        # Eliminamos las filas que hacen de cabecera en los ficheros originales y reseteamos el índice\n",
    "        df.reset_index(inplace=True)\n",
    "        df = df[df.Nombre != 'NAME']\n",
    "        \n",
    "        #DataFrames\n",
    "        dfwork = df[dfwork_cols]\n",
    "        dfaudit = df[dfaudit_cols]\n",
    "        dfparticipadas = df[dfParticipadas_cols]\n",
    "\n",
    "        counter = 1\n",
    "    else:\n",
    "        print 'Resto ficheros:', f\n",
    "        df_temp = pd.read_excel(io, sheetname='Resultados',index_col=None, header=0, skiprows=0, na_values=None, thousands=None)\n",
    "\n",
    "        # Eliminamos las filas que hacen de cabecera en los ficheros originales y reseteamos el índice\n",
    "        df_temp.reset_index(inplace=True)\n",
    "        df_temp = df_temp[df_temp.Nombre != 'NAME']\n",
    "\n",
    "        #DataFrames\n",
    "        dfwork = dfwork.append(df_temp[dfwork_cols])\n",
    "        dfaudit = dfaudit.append(df_temp[dfaudit_cols])\n",
    "        dfparticipadas = dfparticipadas.append(df_temp[dfParticipadas_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formateamos los diferentes DataFrames que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_index = [u'Nombre', u'Código NIF']\n",
    "\n",
    "#DataFrame de la empresa\n",
    "dfwork2 = dfwork.dropna(subset=cols_index)\n",
    "\n",
    "#DataFrame de auditores\n",
    "dfaudit2 = dfaudit.dropna(subset=[u'Nombre auditor',u'Salvedades'], how='all')\n",
    "dfaudit2[cols_index] = dfaudit2[cols_index].fillna(method='ffill')\n",
    "\n",
    "#DataFrame de participadas\n",
    "dfparticipadas2 = dfparticipadas.dropna(subset=[u'Participada - Nombre'])\n",
    "dfparticipadas2[cols_index] = dfparticipadas2[cols_index].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos los DataFrames a ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfwork_file = 'dfwork'\n",
    "dfaudit_file = 'dfaudit'\n",
    "dfparticipadas_file = 'dfparticipadas'\n",
    "\n",
    "if (not(os.path.isfile(dfwork_file))):\n",
    "    with open(dfwork_file, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(dfwork2, dumpPickleCounter)\n",
    "else:\n",
    "    with open(dfwork_file, 'rb') as dumpPickleCounter:\n",
    "        dfwork2 = pickle.load(dumpPickleCounter)\n",
    "        \n",
    "if (not(os.path.isfile(dfaudit_file))):\n",
    "    with open(dfaudit_file, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(dfaudit2, dumpPickleCounter)\n",
    "else:\n",
    "    with open(dfaudit_file, 'rb') as dumpPickleCounter:\n",
    "        dfaudit2 = pickle.load(dumpPickleCounter)\n",
    "        \n",
    "if (not(os.path.isfile(dfparticipadas_file))):\n",
    "    with open(dfparticipadas_file, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(dfparticipadas2, dumpPickleCounter)\n",
    "else:\n",
    "    with open(dfparticipadas_file, 'rb') as dumpPickleCounter:\n",
    "        dfparticipadas2 = pickle.load(dumpPickleCounter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## SABI 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12 Lista2 Empresas 90001_97000.xlsx', '25 Lista2 Empresas 181001-188000.xlsx', '01 Lista2 Empresas 1_7500.xlsx', '02 Lista2 Empresas 7501_15000.xlsx', '03 Lista2 Empresas 15001_22501.xlsx', '04 Lista2 Empresas 22502_30001.xlsx', '05 Lista 2 Empresas 30002_37501.xlsx', '06 Lista2 Empresas 37502_45001.xlsx', '07 Lista2 Empresas 45002-52501.xlsx', '08 Lista2 Empresas 52502_60001.xlsx', '09 Lista2 Empresas 60002_67501.xlsx', '10 Lista2 Empresas 67501_75001.xlsx', '11 Lista2 Empresas 75002_82501.xlsx', '12 Lista2 Empresas 82501_90001.xlsx', '13 Lista2 Empresas 97001_104000.xlsx', '14 Lista2 Empresas 104001_111000.xlsx', '15 Lista2 Empresas 111001_118000.xlsx', '16 Lista2 Empresas 181001_125000.xlsx', '17 Lista2 Empresas 125001_132000.xlsx', '18 Lista2 Empresas 132000-139000.xlsx', '19 Lista2 Empresas 139001-146000.xlsx', '20 Lista2 Empresas 146001_153000.xlsx', '21 Lista2 Empresas 153001-160000.xlsx', '22 Lista2 Empresas 160001-167000.xlsx', '23 Lista2 Empresas 167001-174000.xlsx', '24 Lista2 Empresas 174001-181000.xlsx', '26 Lista2 Empresas 188001_195000.xlsx', '27 Lista2 Empresas 195001-202000.xlsx', '28 Lista2 Empresas 202001-209000.xlsx', '29 Lista2 Empresas 209001-216000.xlsx', '30 Lista2 Empresas 216001-223000.xlsx', '31 Lista2 Empresas 223001_230000.xlsx', '32 Lista2 Empresas 230001_233000.xlsx', '33 Lista2 empresas 233001-240000.xlsx', '34 Lista2 Empresas 240001-247000.xlsx', '35 Lista2 Empresas 247001-254000.xlsx', '36 Lista2 Empresas 254001-261000.xlsx', '37 Lista2 Empresas 261001-268000.xlsx', '38 Lista2 Empresas 268001-275000.xlsx', '39 Lista2 Empresas 275001-280115.xlsx']\n"
     ]
    }
   ],
   "source": [
    "counter_file_name2 = 'file_processed_counter2'\n",
    "\n",
    "path2 = 'SABI Lista2/'\n",
    "onlyfiles2 = [f for f in listdir(path2) if isfile(join(path2, f))]\n",
    "\n",
    "#Cargamos en un vector, la lista de los ficheros que se van procesando, por si se cae el jupyter, no volver a procesar todos\n",
    "#Sino proseguir con aquellos que no se han procesado.\n",
    "if (not(os.path.isfile(counter_file_name2))):\n",
    "    with open(counter_file_name, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(onlyfiles2, dumpPickleCounter)\n",
    "else:\n",
    "    with open(counter_file_name2, 'rb') as dumpPickleCounter:\n",
    "        onlyfiles2 = pickle.load(dumpPickleCounter)\n",
    "\n",
    "print onlyfiles2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfjunta_cols = [1,2,16,17,18,19,20,21,3,4,5,6,7,8,9,10,11,12,13,14,15,22,24]\n",
    "dfaccionistas_cols = [1,2,25,26,27,28,29,30,31,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer fichero: 12 Lista2 Empresas 90001_97000.xlsx\n",
      "Resto ficheros: 25 Lista2 Empresas 181001-188000.xlsx\n",
      "Resto ficheros: 01 Lista2 Empresas 1_7500.xlsx\n",
      "Resto ficheros: 02 Lista2 Empresas 7501_15000.xlsx\n",
      "Resto ficheros: 03 Lista2 Empresas 15001_22501.xlsx\n",
      "Resto ficheros: 04 Lista2 Empresas 22502_30001.xlsx\n",
      "Resto ficheros: 05 Lista 2 Empresas 30002_37501.xlsx\n",
      "Resto ficheros: 06 Lista2 Empresas 37502_45001.xlsx\n",
      "Resto ficheros: 07 Lista2 Empresas 45002-52501.xlsx\n",
      "Resto ficheros: 08 Lista2 Empresas 52502_60001.xlsx\n",
      "Resto ficheros: 09 Lista2 Empresas 60002_67501.xlsx\n",
      "Resto ficheros: 10 Lista2 Empresas 67501_75001.xlsx\n",
      "Resto ficheros: 11 Lista2 Empresas 75002_82501.xlsx\n",
      "Resto ficheros: 12 Lista2 Empresas 82501_90001.xlsx\n",
      "Resto ficheros: 13 Lista2 Empresas 97001_104000.xlsx\n",
      "Resto ficheros: 14 Lista2 Empresas 104001_111000.xlsx\n",
      "Resto ficheros: 15 Lista2 Empresas 111001_118000.xlsx\n",
      "Resto ficheros: 16 Lista2 Empresas 181001_125000.xlsx\n",
      "Resto ficheros: 17 Lista2 Empresas 125001_132000.xlsx\n",
      "Resto ficheros: 18 Lista2 Empresas 132000-139000.xlsx\n",
      "Resto ficheros: 19 Lista2 Empresas 139001-146000.xlsx\n",
      "Resto ficheros: 20 Lista2 Empresas 146001_153000.xlsx\n",
      "Resto ficheros: 21 Lista2 Empresas 153001-160000.xlsx\n",
      "Resto ficheros: 22 Lista2 Empresas 160001-167000.xlsx\n",
      "Resto ficheros: 23 Lista2 Empresas 167001-174000.xlsx\n",
      "Resto ficheros: 24 Lista2 Empresas 174001-181000.xlsx\n",
      "Resto ficheros: 26 Lista2 Empresas 188001_195000.xlsx\n",
      "Resto ficheros: 27 Lista2 Empresas 195001-202000.xlsx\n",
      "Resto ficheros: 28 Lista2 Empresas 202001-209000.xlsx\n",
      "Resto ficheros: 29 Lista2 Empresas 209001-216000.xlsx\n",
      "Resto ficheros: 30 Lista2 Empresas 216001-223000.xlsx\n",
      "Resto ficheros: 31 Lista2 Empresas 223001_230000.xlsx\n",
      "Resto ficheros: 32 Lista2 Empresas 230001_233000.xlsx\n",
      "Resto ficheros: 33 Lista2 empresas 233001-240000.xlsx\n",
      "Resto ficheros: 34 Lista2 Empresas 240001-247000.xlsx\n",
      "Resto ficheros: 35 Lista2 Empresas 247001-254000.xlsx\n",
      "Resto ficheros: 36 Lista2 Empresas 254001-261000.xlsx\n",
      "Resto ficheros: 37 Lista2 Empresas 261001-268000.xlsx\n",
      "Resto ficheros: 38 Lista2 Empresas 268001-275000.xlsx\n",
      "Resto ficheros: 39 Lista2 Empresas 275001-280115.xlsx\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "dfjunta = pd.DataFrame()\n",
    "dfaccionistas = pd.DataFrame()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for f in list(onlyfiles2):\n",
    "    io = join(path2, f)\n",
    "    if counter==0:\n",
    "        print 'Primer fichero:', f\n",
    "        df = pd.read_excel(io, sheetname='Resultados', index_col=None, header=0, skiprows=0, na_values=None, thousands=None)\n",
    "        \n",
    "        # Eliminamos las filas que hacen de cabecera en los ficheros originales y reseteamos el índice\n",
    "        df.reset_index(inplace=True)\n",
    "        df = df[df.Nombre != 'NAME']\n",
    "        \n",
    "        #DataFrames\n",
    "        dfjunta = df[dfjunta_cols]\n",
    "        dfaccionistas = df[dfaccionistas_cols]\n",
    "\n",
    "        counter = 1\n",
    "    else:\n",
    "        print 'Resto ficheros:', f\n",
    "        df_temp = pd.read_excel(io, sheetname='Resultados',index_col=None, header=0, skiprows=0, na_values=None, thousands=None)\n",
    "\n",
    "        # Eliminamos las filas que hacen de cabecera en los ficheros originales y reseteamos el índice\n",
    "        df_temp.reset_index(inplace=True)\n",
    "        df_temp = df_temp[df_temp.Nombre != 'NAME']\n",
    "\n",
    "        #DataFrames\n",
    "        dfjunta = dfjunta.append(df_temp[dfjunta_cols])\n",
    "        dfaccionistas = dfaccionistas.append(df_temp[dfaccionistas_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#DataFrame de la junta\n",
    "dfjunta2 = dfjunta.dropna(subset=cols_index)\n",
    "\n",
    "#DataFrame de accionistas\n",
    "dfaccionistas2 = dfaccionistas.dropna(subset=[u'Nombre accionista'])\n",
    "dfaccionistas2[cols_index] = dfaccionistas2[cols_index].fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos los DataFrames a ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfjunta_file = 'dfjunta'\n",
    "dfaccionistas_file = 'dfaccionistas'\n",
    "\n",
    "if (not(os.path.isfile(dfjunta_file))):\n",
    "    with open(dfjunta_file, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(dfwork2, dumpPickleCounter)\n",
    "else:\n",
    "    with open(dfjunta_file, 'rb') as dumpPickleCounter:\n",
    "        dfjunta2 = pickle.load(dumpPickleCounter)\n",
    "        \n",
    "if (not(os.path.isfile(dfaccionistas_file))):\n",
    "    with open(dfaccionistas_file, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(dfaccionistas2, dumpPickleCounter)\n",
    "else:\n",
    "    with open(dfaccionistas_file, 'rb') as dumpPickleCounter:\n",
    "        dfaccionistas2 = pickle.load(dumpPickleCounter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SABI 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J. 360001-405000.xlsx', 'G. 225001-270000.xlsx', 'D. 135001-180000.xlsx', 'F. 185001-225000.xlsx', 'C. 90001-135000.xlsx', 'K. 405001-450000.xlsx', 'L. 450001-495000.xlsx', 'H. 270001-315000.xlsx', 'A. 1-45000.xlsx', 'B. 45001-90000.xlsx', 'I. 315001-360000.xlsx', 'M. 495001-532592.xlsx', 'E. 180001-185000.xlsx']\n"
     ]
    }
   ],
   "source": [
    "counter_file_name = 'file_processed_counter'\n",
    "\n",
    "path3 = '../../data/datasets/SABI2'\n",
    "onlyfiles3 = [f for f in listdir(path3) if isfile(join(path3, f))]\n",
    "\n",
    "#Cargamos en un vector, la lista de los ficheros que se van procesando, por si se cae el jupyter, no volver a procesar todos\n",
    "#Sino proseguir con aquellos que no se han procesado.\n",
    "if (not(os.path.isfile(counter_file_name))):\n",
    "    with open(counter_file_name, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(onlyfiles3, dumpPickleCounter)\n",
    "else:\n",
    "    with open(counter_file_name, 'rb') as dumpPickleCounter:\n",
    "        onlyfiles3 = pickle.load(dumpPickleCounter)\n",
    "\n",
    "print onlyfiles3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las columnas que vamos a coger para cada DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfwork_cols = [1,2,3,4,5,7,8,11,20,21]\n",
    "dfaudit_cols = [1,2,3,16,17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer fichero: J. 360001-405000.xlsx\n",
      "Resto ficheros: G. 225001-270000.xlsx\n",
      "Resto ficheros: D. 135001-180000.xlsx\n",
      "Resto ficheros: F. 185001-225000.xlsx\n",
      "Resto ficheros: C. 90001-135000.xlsx\n",
      "Resto ficheros: K. 405001-450000.xlsx\n",
      "Resto ficheros: L. 450001-495000.xlsx\n",
      "Resto ficheros: H. 270001-315000.xlsx\n",
      "Resto ficheros: A. 1-45000.xlsx\n",
      "Resto ficheros: B. 45001-90000.xlsx\n",
      "Resto ficheros: I. 315001-360000.xlsx\n",
      "Resto ficheros: M. 495001-532592.xlsx\n",
      "Resto ficheros: E. 180001-185000.xlsx\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "dfwork = pd.DataFrame()\n",
    "dfaudit = pd.DataFrame()\n",
    "\n",
    "counter = 0\n",
    "\n",
    "for f in list(onlyfiles3):\n",
    "    io = join(path3, f)\n",
    "    if counter==0:\n",
    "        print 'Primer fichero:', f\n",
    "        df = pd.read_excel(io, sheetname='Resultados', index_col=None, header=0, skiprows=0, na_values=None, thousands=None)\n",
    "        \n",
    "        # Eliminamos las filas que hacen de cabecera en los ficheros originales y reseteamos el índice\n",
    "        df.reset_index(inplace=True)\n",
    "        df = df[df.Nombre != 'NAME']\n",
    "        \n",
    "        #DataFrames\n",
    "        dfwork = df[dfwork_cols]\n",
    "        dfaudit = df[dfaudit_cols]\n",
    "\n",
    "        counter = 1\n",
    "    else:\n",
    "        print 'Resto ficheros:', f\n",
    "        df_temp = pd.read_excel(io, sheetname='Resultados',index_col=None, header=0, skiprows=0, na_values=None, thousands=None)\n",
    "\n",
    "        # Eliminamos las filas que hacen de cabecera en los ficheros originales y reseteamos el índice\n",
    "        df_temp.reset_index(inplace=True)\n",
    "        df_temp = df_temp[df_temp.Nombre != 'NAME']\n",
    "\n",
    "        #DataFrames\n",
    "        dfwork = dfwork.append(df_temp[dfwork_cols])\n",
    "        dfaudit = dfaudit.append(df_temp[dfaudit_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formateamos los diferentes DataFrames que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Código NIF</th>\n",
       "      <th>Número BvD</th>\n",
       "      <th>Fecha constitución</th>\n",
       "      <th>Estado</th>\n",
       "      <th>Código primario CNAE 2009</th>\n",
       "      <th>Incidencias Judiciales</th>\n",
       "      <th>Reclamaciones administrativas</th>\n",
       "      <th>Coordenada - X</th>\n",
       "      <th>Coordenada - Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPACIO ELECTRICO SL</td>\n",
       "      <td>B84860568</td>\n",
       "      <td>ESB84860568</td>\n",
       "      <td>2006-09-25 00:00:00</td>\n",
       "      <td>Activa</td>\n",
       "      <td>4321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.67824</td>\n",
       "      <td>40.350476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Nombre Código NIF   Número BvD   Fecha constitución  Estado  \\\n",
       "1  ESPACIO ELECTRICO SL  B84860568  ESB84860568  2006-09-25 00:00:00  Activa   \n",
       "2                   NaN        NaN          NaN                  NaN     NaN   \n",
       "\n",
       "  Código primario CNAE 2009 Incidencias Judiciales  \\\n",
       "1                      4321                    NaN   \n",
       "2                       NaN                    NaN   \n",
       "\n",
       "  Reclamaciones administrativas Coordenada - X Coordenada - Y  \n",
       "1                           NaN       -3.67824      40.350476  \n",
       "2                           NaN            NaN            NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfwork.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Código NIF</th>\n",
       "      <th>Número BvD</th>\n",
       "      <th>Nombre auditor</th>\n",
       "      <th>Salvedades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ESPACIO ELECTRICO SL</td>\n",
       "      <td>B84860568</td>\n",
       "      <td>ESB84860568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ESPACIO ELECTRICO SL</td>\n",
       "      <td>B84860568</td>\n",
       "      <td>ESB84860568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Nombre Código NIF   Número BvD Nombre auditor Salvedades\n",
       "1  ESPACIO ELECTRICO SL  B84860568  ESB84860568            NaN        NaN\n",
       "2  ESPACIO ELECTRICO SL  B84860568  ESB84860568            NaN        NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfaudit.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_index = [u'Nombre', u'Código NIF', u'Número BvD']\n",
    "\n",
    "#DataFrame de la empresa\n",
    "#Quitar bancos (CNAE 641)\n",
    "dfwork3 = dfwork.dropna(subset=cols_index)\n",
    "\n",
    "#DataFrame de auditores\n",
    "dfaudit[cols_index] = dfaudit[cols_index].fillna(method='ffill')\n",
    "dfaudit3 = dfaudit.dropna(subset=[u'Nombre auditor',u'Salvedades'], how='all')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos los DataFrames a ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfwork_file = 'dfwork3'\n",
    "dfaudit_file = 'dfaudit3'\n",
    "\n",
    "if (not(os.path.isfile(dfwork_file))):\n",
    "    with open(dfwork_file, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(dfwork3, dumpPickleCounter)\n",
    "else:\n",
    "    with open(dfwork_file, 'rb') as dumpPickleCounter:\n",
    "        dfwork3 = pickle.load(dumpPickleCounter)\n",
    "        \n",
    "if (not(os.path.isfile(dfaudit_file))):\n",
    "    with open(dfaudit_file, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(dfaudit3, dumpPickleCounter)\n",
    "else:\n",
    "    with open(dfaudit_file, 'rb') as dumpPickleCounter:\n",
    "        dfaudit3 = pickle.load(dumpPickleCounter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Código NIF</th>\n",
       "      <th>Número BvD</th>\n",
       "      <th>Nombre auditor</th>\n",
       "      <th>Salvedades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4426</th>\n",
       "      <td>ALVAREZ FRA SA</td>\n",
       "      <td>A28995231</td>\n",
       "      <td>ESA28995231</td>\n",
       "      <td>MGR DE AUDITORIA Y CONSULTORIA S.L.</td>\n",
       "      <td>Aprobado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4428</th>\n",
       "      <td>ALVAREZ FRA SA</td>\n",
       "      <td>A28995231</td>\n",
       "      <td>ESA28995231</td>\n",
       "      <td>MGR DE AUDITORIA Y CONSULTORIA S.L.</td>\n",
       "      <td>Aprobado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58866</th>\n",
       "      <td>RAILTECH SUFETRA SA</td>\n",
       "      <td>A08008567</td>\n",
       "      <td>ESA08008567</td>\n",
       "      <td>MGR DE AUDITORIA Y CONSULTORIA S.L.</td>\n",
       "      <td>Aprobado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58867</th>\n",
       "      <td>RAILTECH SUFETRA SA</td>\n",
       "      <td>A08008567</td>\n",
       "      <td>ESA08008567</td>\n",
       "      <td>MGR DE AUDITORIA Y CONSULTORIA S.L.</td>\n",
       "      <td>Aprobado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58869</th>\n",
       "      <td>RAILTECH SUFETRA SA</td>\n",
       "      <td>A08008567</td>\n",
       "      <td>ESA08008567</td>\n",
       "      <td>MGR DE AUDITORIA Y CONSULTORIA S.L.</td>\n",
       "      <td>Aprobado</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Nombre Código NIF   Número BvD  \\\n",
       "4426        ALVAREZ FRA SA  A28995231  ESA28995231   \n",
       "4428        ALVAREZ FRA SA  A28995231  ESA28995231   \n",
       "58866  RAILTECH SUFETRA SA  A08008567  ESA08008567   \n",
       "58867  RAILTECH SUFETRA SA  A08008567  ESA08008567   \n",
       "58869  RAILTECH SUFETRA SA  A08008567  ESA08008567   \n",
       "\n",
       "                            Nombre auditor Salvedades  \n",
       "4426   MGR DE AUDITORIA Y CONSULTORIA S.L.   Aprobado  \n",
       "4428   MGR DE AUDITORIA Y CONSULTORIA S.L.   Aprobado  \n",
       "58866  MGR DE AUDITORIA Y CONSULTORIA S.L.   Aprobado  \n",
       "58867  MGR DE AUDITORIA Y CONSULTORIA S.L.   Aprobado  \n",
       "58869  MGR DE AUDITORIA Y CONSULTORIA S.L.   Aprobado  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfaudit3[dfaudit3[u'Nombre auditor'] == 'MGR DE AUDITORIA Y CONSULTORIA S.L.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SABI 4 (CNAE 641)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las columnas que vamos a coger para cada DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfbanks_cols = [1,2,3,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primer fichero: /home/ec2-user/proyecto/tfm/notebooks/CNAE 641.xlsx\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "dfbanks = pd.DataFrame()\n",
    "\n",
    "f = '/home/ec2-user/proyecto/tfm/notebooks/CNAE 641.xlsx'\n",
    "\n",
    "print 'Primer fichero:', f\n",
    "\n",
    "df = pd.read_excel(f, sheetname='Resultados', index_col=None, header=0, skiprows=0, na_values=None, thousands=None)\n",
    "        \n",
    "# Eliminamos las filas que hacen de cabecera en los ficheros originales y reseteamos el índice\n",
    "df.reset_index(inplace=True)\n",
    "df = df[df.Nombre != 'NAME']\n",
    "        \n",
    "#DataFrames\n",
    "dfbanks = df[dfbanks_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formateamos los diferentes DataFrames que vamos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols_index = [u'Nombre', u'Código NIF', u'Número BvD']\n",
    "\n",
    "#DataFrame de la empresa\n",
    "dfbanks = dfbanks.dropna(subset=cols_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasamos los DataFrames a ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfbanks_file = 'dfbanks3'\n",
    "\n",
    "if (not(os.path.isfile(dfbanks_file))):\n",
    "    with open(dfbanks_file, 'wb') as dumpPickleCounter:\n",
    "        pickle.dump(dfbanks, dumpPickleCounter)\n",
    "else:\n",
    "    with open(dfbanks_file, 'rb') as dumpPickleCounter:\n",
    "        dfbanks = pickle.load(dumpPickleCounter)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
